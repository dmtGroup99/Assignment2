#load data
data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
#preprocess data
source("data_scripts_v2/iteration3_v2.R")
data_new <- iteration3(data, 0.8)
#train xgboost
library(xgboost)
train <- data_new$train[order(data_new$train$srch_id),]
counts <- data.frame(table(data_new$train$srch_id))
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,13,32)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,13,31)]))
#listwise model (lambdaMart)
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
#calculate variable importance and create graph
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
predictions <- predict(bst,dtest)
id <- data_new$test$srch_id
label <- data_new$test$target
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
colnames(train)
colnames(data_new$test)
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,13,32)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,31)]))
predictions <- predict(bst,dtest)
id <- data_new$test$srch_id
label <- data_new$test$target
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
metric
source("data_scripts_v2/iteration3_v2.R")
data_new <- iteration3(data, 0.8)
#train xgboost
library(xgboost)
train <- data_new$train[order(data_new$train$srch_id),]
counts <- data.frame(table(data_new$train$srch_id))
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,13,32)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,31)]))
#listwise model (lambdaMart)
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
#calculate variable importance and create graph
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
#Calculate NDCG
predictions <- predict(bst,dtest)
id <- data_new$test$srch_id
label <- data_new$test$target
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
metric
setwd("~/Desktop/Assignment2/iterations")
setwd("~/Desktop/Assignment2")
setwd("~/Desktop/Assignment2/data_scripts_v2")
library(data.table)
#load data
data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
#preprocess data
source("data_scripts_v2/iteration4_v2.R")
data_new <- iteration4(data, 0.8)
#train xgboost
library(xgboost)
train <- data_new$train[order(data_new$train$srch_id),]
counts <- data.frame(table(data_new$train$srch_id))
colnames(train)
colnames(data_new$test)
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,13,32)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,31)]))
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
colnames(train)
colnames(data_new$test)
library(data.table)
#load data
data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
#preprocess data
source("data_scripts_v2/iteration4_v2.R")
data_new <- iteration4(data, 0.8)
source("data_scripts_v2/iteration4_v2.R")
setwd("~/Desktop/Assignment2")
source("data_scripts_v2/iteration4_v2.R")
data_new <- iteration4(data, 0.8)
colnames(data_new$train)
colnames(data_new$test)
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,31)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,31)]))
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
colnames(train)
colnames(data_new$train)
train <- data_new$train[order(data_new$train$srch_id),]
colnames(train)
counts <- data.frame(table(train$srch_id))
colnames(train)
colnames(data_new$test)
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,31)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,31)]))
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
predictions <- predict(bst,dtest)
id <- data_new$test$srch_id
label <- data_new$test$target
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
metric
setwd("~/Desktop/Assignment2/iterations")
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 300, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
predictions <- predict(bst,dtest)
id <- data_new$test$srch_id
label <- data_new$test$target
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
setwd("~/Desktop/Assignment2")
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
setwd("~/Desktop/Assignment2/data_scripts_v2")
setwd("~/Desktop/Assignment2/iterations")
setwd("~/Desktop/Assignment2")
source("data_scripts_v2/iteration5_v2.R")
data_new <- iteration5(data, 0.8)
source("data_scripts_v2/iteration5_v2.R")
data_new <- iteration5(data, 0.8)
missing_percentage <- apply(data, 2, function(col) sum(is.na(col))/length(col))
keep <- names(missing_percentage[missing_percentage<0.8])
data_ver2 <- subset(data, select = keep)
keep_id <- unique(data_ver2$srch_id)
dt <- sample(keep_id, train_instances*length(keep_id))
train <- subset(data_ver2, srch_id %in% dt)
test <- subset(data_ver2, !(srch_id %in% dt))
num <- train[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_length_of_stay","srch_booking_window","srch_adults_count","srch_children_count",
"srch_room_count","orig_destination_distance", "position")]
nom <- train[,c("srch_id", "site_id", "visitor_location_country_id", "prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "srch_saturday_night_bool", "random_bool",
"comp2_rate", "comp2_inv", "comp3_rate", "comp3_inv", "comp5_rate", "comp5_inv", "comp8_rate", "comp8_inv")]
num_median <- apply(num, 2, function(x) median(x, na.rm = TRUE))
nom_occur <- apply(nom, 2, function(x) names(which.max(table(x))))
numeric_median <- function(x, num_median){
for(i in 1:length(x[1,])){
x[,i][is.na(x[,i])] <- unname(num_median[i])
}
return(x)
}
nominal_occurence <- function(x, nom_occur){
for(i in 1:length(x[1,])){
x[,i][is.na(x[,i])] <- unname(nom_occur[i])
}
return(x)
}
num <- numeric_median(num, num_median)
nom <- nominal_occurence(nom, nom_occur)
nom <- as.data.frame(lapply(nom, function(x) as.numeric(as.character(x))))
target <- train$booking_bool + train$click_bool
target[target==2] <- 5
train_set <- cbind(num, nom, target, booking_bool=train$booking_bool, click_bool=train$click_bool)
positionmedian <- with(train_set, tapply(position, prop_id, function(x) median(x)))
key <- data.frame(median_postition = unname(positionmedian), id = names(positionmedian))
train_set$estimate_position <- key[match(train_set$prop_id, key$id), "median_postition"]
train_set$position <- NULL
train_set$propscore1diff <- with(train_set, unlist(tapply(prop_location_score1, srch_id, function(x) x-mean(x))))
train_set$propscore2diff <- with(train_set, unlist(tapply(prop_location_score2, srch_id, function(x) x-mean(x))))
train_set$propreviewscorediff <- with(train_set, unlist(tapply(prop_review_score, srch_id, function(x) x-mean(x))))
train_set$propstarratingdiff <- with(train_set, unlist(tapply(prop_starrating, srch_id, function(x) x-mean(x))))
train_set$priceusddiff <- with(train_set, unlist(tapply(price_usd, srch_id, function(x) x-mean(x))))
number_bookings_hotel <- with(train_set, tapply(booking_bool, prop_id, function(x) sum(x)))
number_clicks_hotel <- with(train_set, tapply(click_bool, prop_id, function(x) sum(x)))
number_appereance_hotel <- with(train_set, tapply(target, prop_id, function(x) length(x)))
popularity = (number_bookings_hotel/number_clicks_hotel)*number_appereance_hotel
popularity[is.nan(popularity)] <- 0
key <- data.frame(popularity = unname(popularity), id = names(popularity))
train_set$popularity <- key[match(train_set$prop_id, key$id), "popularity"]
train_set$booking_bool <- NULL
train_set$click_bool <- NULL
num <- test[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_length_of_stay","srch_booking_window","srch_adults_count","srch_children_count",
"srch_room_count","orig_destination_distance")]
nom <- test[,c("srch_id", "site_id", "visitor_location_country_id", "prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "srch_saturday_night_bool", "random_bool",
"comp2_rate", "comp2_inv", "comp3_rate", "comp3_inv", "comp5_rate", "comp5_inv", "comp8_rate", "comp8_inv")]
num <- numeric_median(num, num_median)
nom <- nominal_occurence(nom, nom_occur)
nom <- as.data.frame(lapply(nom, function(x) as.numeric(as.character(x))))
target <- test$booking_bool + test$click_bool
target[target==2] <- 5
test_set <- cbind(num, nom, target)
d <- subset(test_set, !(test_set$prop_id %in% train_set$prop_id))
key2 <- data.frame(median_postition = median(positionmedian), id = as.factor(unique(d$prop_id)))
key_final <- rbind(key,key2)
head(key)
missing_percentage <- apply(data, 2, function(col) sum(is.na(col))/length(col))
#This will give 34 variables
keep <- names(missing_percentage[missing_percentage<0.8])
data_ver2 <- subset(data, select = keep)
keep_id <- unique(data_ver2$srch_id)
#split data random into train and test
dt <- sample(keep_id, train_instances*length(keep_id))
train <- subset(data_ver2, srch_id %in% dt)
test <- subset(data_ver2, !(srch_id %in% dt))
#split data into numerical and nominal values (check this!)
num <- train[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_length_of_stay","srch_booking_window","srch_adults_count","srch_children_count",
"srch_room_count","orig_destination_distance", "position")]
nom <- train[,c("srch_id", "site_id", "visitor_location_country_id", "prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "srch_saturday_night_bool", "random_bool",
"comp2_rate", "comp2_inv", "comp3_rate", "comp3_inv", "comp5_rate", "comp5_inv", "comp8_rate", "comp8_inv")]
num_median <- apply(num, 2, function(x) median(x, na.rm = TRUE))
nom_occur <- apply(nom, 2, function(x) names(which.max(table(x))))
numeric_median <- function(x, num_median){
for(i in 1:length(x[1,])){
x[,i][is.na(x[,i])] <- unname(num_median[i])
}
return(x)
}
nominal_occurence <- function(x, nom_occur){
for(i in 1:length(x[1,])){
x[,i][is.na(x[,i])] <- unname(nom_occur[i])
}
return(x)
}
num <- numeric_median(num, num_median)
nom <- nominal_occurence(nom, nom_occur)
#make numeric
nom <- as.data.frame(lapply(nom, function(x) as.numeric(as.character(x))))
#give relevance scores (clicked -> 1, booked -> 5 and other -> 0)
target <- train$booking_bool + train$click_bool
target[target==2] <- 5
train_set <- cbind(num, nom, target, booking_bool=train$booking_bool, click_bool=train$click_bool)
#calculate position
positionmedian <- with(train_set, tapply(position, prop_id, function(x) median(x)))
key_position <- data.frame(median_postition = unname(positionmedian), id = names(positionmedian))
train_set$estimate_position <- key_position[match(train_set$prop_id, key_position$id), "median_postition"]
train_set$position <- NULL
#calculating differences with respect to mean of search query numerical values
train_set$propscore1diff <- with(train_set, unlist(tapply(prop_location_score1, srch_id, function(x) x-mean(x))))
train_set$propscore2diff <- with(train_set, unlist(tapply(prop_location_score2, srch_id, function(x) x-mean(x))))
train_set$propreviewscorediff <- with(train_set, unlist(tapply(prop_review_score, srch_id, function(x) x-mean(x))))
train_set$propstarratingdiff <- with(train_set, unlist(tapply(prop_starrating, srch_id, function(x) x-mean(x))))
train_set$priceusddiff <- with(train_set, unlist(tapply(price_usd, srch_id, function(x) x-mean(x))))
#calculate popularity
number_bookings_hotel <- with(train_set, tapply(booking_bool, prop_id, function(x) sum(x)))
number_clicks_hotel <- with(train_set, tapply(click_bool, prop_id, function(x) sum(x)))
number_appereance_hotel <- with(train_set, tapply(target, prop_id, function(x) length(x)))
popularity = (number_bookings_hotel/number_clicks_hotel)*number_appereance_hotel
popularity[is.nan(popularity)] <- 0
key_pop <- data.frame(popularity = unname(popularity), id = names(popularity))
train_set$popularity <- key_pop[match(train_set$prop_id, key_pop$id), "popularity"]
train_set$booking_bool <- NULL
train_set$click_bool <- NULL
#split data into numerical and nominal values (check this!)
num <- test[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_length_of_stay","srch_booking_window","srch_adults_count","srch_children_count",
"srch_room_count","orig_destination_distance")]
nom <- test[,c("srch_id", "site_id", "visitor_location_country_id", "prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "srch_saturday_night_bool", "random_bool",
"comp2_rate", "comp2_inv", "comp3_rate", "comp3_inv", "comp5_rate", "comp5_inv", "comp8_rate", "comp8_inv")]
num <- numeric_median(num, num_median)
nom <- nominal_occurence(nom, nom_occur)
#make numeric
nom <- as.data.frame(lapply(nom, function(x) as.numeric(as.character(x))))
#give relevance scores (clicked -> 1, booked -> 5 and other -> 0)
target <- test$booking_bool + test$click_bool
target[target==2] <- 5
test_set <- cbind(num, nom, target)
#calculate position
d <- subset(test_set, !(test_set$prop_id %in% train_set$prop_id))
key2 <- data.frame(median_postition = median(positionmedian), id = as.factor(unique(d$prop_id)))
key_final <- rbind(key_position,key2)
#key_final <- subset(key_final, test_set$prop_id %in% key_final$id)
test_set$estimate_position <- key_final[match(test_set$prop_id, key_final$id), "median_postition"]
test_set$position <- NULL
#calculate features
test_set$propscore1diff <- with(test_set, unlist(tapply(prop_location_score1, srch_id, function(x) x-mean(x))))
test_set$propscore2diff <- with(test_set, unlist(tapply(prop_location_score2, srch_id, function(x) x-mean(x))))
test_set$propreviewscorediff <- with(test_set, unlist(tapply(prop_review_score, srch_id, function(x) x-mean(x))))
test_set$propstarratingdiff <- with(test_set, unlist(tapply(prop_starrating, srch_id, function(x) x-mean(x))))
test_set$priceusddiff <- with(test_set, unlist(tapply(price_usd, srch_id, function(x) x-mean(x))))
#calculate popularity
d <- subset(test_set, !(test_set$prop_id %in% train_set$prop_id))
key2 <- data.frame(popularity = median(popularity), id = as.factor(unique(d$prop_id)))
key_final <- rbind(key_pop,key2)
test_set$popularity <- key_final[match(test_set$prop_id, key_final$id), "popularity"]
colnames(train_set)
colnames(test_set)
data_new <- list()
data_new$train <- train_set
data_new$test <- test_set
train <- data_new$train[order(data_new$train$srch_id),]
counts <- data.frame(table(train$srch_id))
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,31)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,31)]))
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 300, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
predictions <- predict(bst,dtest)
id <- data_new$test$srch_id
label <- data_new$test$target
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
metric
setwd("~/Desktop/Assignment2/data_scripts_v2")
setwd("~/Desktop/Assignment2/iterations")
setwd("~/Desktop/Assignment2")
library(data.table)
#load data
data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
#preprocess data
source("data_scripts_v2/iteration6_v2.R")
data_new <- iteration6(data, 0.8)
#train xgboost
library(xgboost)
train <- data_new$train[order(data_new$train$srch_id),]
counts <- data.frame(table(train$srch_id))
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,31)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,31)]))
#listwise model (lambdaMart)
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
#calculate variable importance and create graph
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
#Calculate NDCG
predictions <- predict(bst,dtest)
id <- data_new$test$srch_id
label <- data_new$test$target
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
metric
setwd("~/Desktop/Assignment2/data_scripts_v2")
setwd("~/Desktop/Assignment2/iterations")
setwd("~/Desktop/Assignment2")
source("data_scripts_v2/iteration7.R")
data_new <- iteration7(data, 0.8)
#train xgboost
library(xgboost)
train <- data_new$train[order(data_new$train$srch_id),]
counts <- data.frame(table(train$srch_id))
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,31)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,31)]))
#listwise model (lambdaMart)
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
colnames(train)
colnames(data_new$test)
source("data_scripts_v2/iteration7.R")
data_new <- iteration7(data, 0.8)
#train xgboost
library(xgboost)
train <- data_new$train[order(data_new$train$srch_id),]
counts <- data.frame(table(train$srch_id))
colnames(train)
colnames(data_new$test)
dtrain <- xgb.DMatrix(as.matrix(train[,-c(8,17)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(8,17)]))
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
predictions <- predict(bst,dtest)
id <- data_new$test$srch_id
label <- data_new$test$target
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
metric
library(data.table)
data <- data.table::fread(input = "../test.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
data2 <- data.table::fread(input = "../test.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
missing_percentage <- apply(data, 2, function(col) sum(is.na(col))/length(col))
#This will give 34 variables
keep <- names(missing_percentage[missing_percentage<0.8])
data_ver2 <- subset(data, select = keep)
keep_id <- unique(data_ver2$srch_id)
#split data random into train and test
dt <- sample(keep_id, train_instances*length(keep_id))
train <- subset(data_ver2, srch_id %in% dt)
test <- subset(data_ver2, !(srch_id %in% dt))
#split data into numerical and nominal values (check this!)
num <- train[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_booking_window",
"orig_destination_distance", "position")]
nom <- train[,c("srch_id", "site_id","prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "random_bool")]
num_median <- apply(num, 2, function(x) median(x, na.rm = TRUE))
nom_occur <- apply(nom, 2, function(x) names(which.max(table(x))))
numeric_median <- function(x, num_median){
for(i in 1:length(x[1,])){
x[,i][is.na(x[,i])] <- unname(num_median[i])
}
return(x)
}
nominal_occurence <- function(x, nom_occur){
for(i in 1:length(x[1,])){
x[,i][is.na(x[,i])] <- unname(nom_occur[i])
}
return(x)
}
num <- numeric_median(num, num_median)
nom <- nominal_occurence(nom, nom_occur)
#make numeric
nom <- as.data.frame(lapply(nom, function(x) as.numeric(as.character(x))))
#give relevance scores (clicked -> 1, booked -> 5 and other -> 0)
target <- train$booking_bool + train$click_bool
target[target==2] <- 5
train_set <- cbind(num, nom, target)
positionmedian <- with(train_set, tapply(position, prop_id, function(x) median(x)))
key <- data.frame(median_postition = unname(positionmedian), id = names(positionmedian))
train_set$estimate_position <- key[match(train_set$prop_id, key$id), "median_postition"]
train_set$position <- NULL
#feature engineering
#calculating differences with respect to mean of search query numerical values
train_set$propscore1diff <- with(train_set, unlist(tapply(prop_location_score1, srch_id, function(x) x-median(x))))
train_set$propscore2diff <- with(train_set, unlist(tapply(prop_location_score2, srch_id, function(x) x-median(x))))
train_set$propreviewscorediff <- with(train_set, unlist(tapply(prop_review_score, srch_id, function(x) x-median(x))))
train_set$propstarratingdiff <- with(train_set, unlist(tapply(prop_starrating, srch_id, function(x) x-median(x))))
train_set$priceusddiff <- with(train_set, unlist(tapply(price_usd, srch_id, function(x) x-median(x))))
#split data into numerical and nominal values (check this!)
num <- test[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_booking_window",
"orig_destination_distance", "position")]
nom <- test[,c("srch_id", "site_id","prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "random_bool")]
num <- numeric_median(num, num_median)
nom <- nominal_occurence(nom, nom_occur)
#make numeric
nom <- as.data.frame(lapply(nom, function(x) as.numeric(as.character(x))))
#give relevance scores (clicked -> 1, booked -> 5 and other -> 0)
target <- test$booking_bool + test$click_bool
target[target==2] <- 5
test_set <- cbind(num, nom, target)
d <- subset(test_set, !(test_set$prop_id %in% train_set$prop_id))
key2 <- data.frame(median_postition = median(positionmedian), id = as.factor(unique(d$prop_id)))
key_final <- rbind(key,key2)
#key_final <- subset(key_final, test_set$prop_id %in% key_final$id)
test_set$estimate_position <- key_final[match(test_set$prop_id, key_final$id), "median_postition"]
test_set$position <- NULL
test_set$propscore1diff <- with(test_set, unlist(tapply(prop_location_score1, srch_id, function(x) x-median(x))))
test_set$propscore2diff <- with(test_set, unlist(tapply(prop_location_score2, srch_id, function(x) x-median(x))))
test_set$propreviewscorediff <- with(test_set, unlist(tapply(prop_review_score, srch_id, function(x) x-median(x))))
test_set$propstarratingdiff <- with(test_set, unlist(tapply(prop_starrating, srch_id, function(x) x-median(x))))
test_set$priceusddiff <- with(test_set, unlist(tapply(price_usd, srch_id, function(x) x-median(x))))
View(ndcg)
View(ndcg)
test <- data2
num <- test[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_booking_window",
"orig_destination_distance", "position")]
colnames(test)
num <- test[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_booking_window",
"orig_destination_distance", "position")]
num <- test[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_booking_window",
"orig_destination_distance")]
nom <- test[,c("srch_id", "site_id","prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "random_bool")]
num <- numeric_median(num, num_median)
nom <- nominal_occurence(nom, nom_occur)
nom <- as.data.frame(lapply(nom, function(x) as.numeric(as.character(x))))
test_set <- cbind(num, nom)
d <- subset(test_set, !(test_set$prop_id %in% train_set$prop_id))
key2 <- data.frame(median_postition = median(positionmedian), id = as.factor(unique(d$prop_id)))
key_final <- rbind(key,key2)
test_set$estimate_position <- key_final[match(test_set$prop_id, key_final$id), "median_postition"]
test_set$propscore1diff <- with(test_set, unlist(tapply(prop_location_score1, srch_id, function(x) x-median(x))))
test_set$propscore2diff <- with(test_set, unlist(tapply(prop_location_score2, srch_id, function(x) x-median(x))))
test_set$propreviewscorediff <- with(test_set, unlist(tapply(prop_review_score, srch_id, function(x) x-median(x))))
test_set$propstarratingdiff <- with(test_set, unlist(tapply(prop_starrating, srch_id, function(x) x-median(x))))
test_set$priceusddiff <- with(test_set, unlist(tapply(price_usd, srch_id, function(x) x-median(x))))
colnames(test)
colnames(test_set)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(8)]))
predictions <- predict(bst,dtest)
head(predictions)
srch_id <- test_set$srch_id
prop_id <- test_set$prop_id
pred <- data.frame(SearchId=srch_id, PropertyId=test_set$prop_id, predictions=predictions)
dtest <- xgb.DMatrix(as.matrix(test_set[,-c(8)]))
predictions <- predict(bst,dtest)
srch_id <- test_set$srch_id
prop_id <- test_set$prop_id
pred <- data.frame(SearchId=srch_id, PropertyId=test_set$prop_id, predictions=predictions)
head(pred,n=2-)
head(pred,n=20)
pred <- pred[order(pred$SearchId, -pred$predictions),]
head(pred,n=20)
write.csv(pred[,c(1,2)], file = "kaggle_pred.csv")
?write
write.csv(pred[,c(1,2)], file = "kaggle_pred.csv", row.names=FALSE)
setwd("~/Desktop/Assignment2")

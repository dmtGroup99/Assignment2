"Venables & Smith"))
books
(m1 <- merge(authors, books, by.x = "surname", by.y = "name"))
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
## use character columns of names to get sensible sort order
authors <- data.frame(
surname = I(c("Tukey", "Venables", "Tierney", "Ripley", "McNeil")),
nationality = c("US", "Australia", "US", "UK", "Australia"),
deceased = c("yes", rep("no", 4)))
## use character columns of names to get sensible sort order
authors <- data.frame(
surname = I(c("Tukey", "Venables", "Tierney", "Ripley", "McNeil")),
nationality = c("US", "Australia", "US", "UK", "Australia"),
deceased = c("yes", rep("no", 4)))
## use character columns of names to get sensible sort order
authors <- data.frame(
surname = I(c("Tukey", "Venables", "Tierney", "Ripley", "McNeil")),
nationality = c("US", "Australia", "US", "UK", "Australia"),
deceased = c("yes", rep("no", 4)))
authors
books <- data.frame(
name = I(c("Tukey", "Venables", "Tierney",
"Ripley", "Ripley", "McNeil", "R Core")),
title = c("Exploratory Data Analysis",
"Modern Applied Statistics ...",
"LISP-STAT",
"Spatial Statistics", "Stochastic Simulation",
"Interactive Data Analysis",
"An Introduction to R"),
other.author = c(NA, "Ripley", NA, NA, NA, NA,
"Venables & Smith"))
books <- data.frame(
name = I(c("Tukey", "Venables", "Tierney",
"Ripley", "Ripley", "McNeil", "R Core")),
title = c("Exploratory Data Analysis",
"Modern Applied Statistics ...",
"LISP-STAT",
"Spatial Statistics", "Stochastic Simulation",
"Interactive Data Analysis",
"An Introduction to R"),
other.author = c(NA, "Ripley", NA, NA, NA, NA,
"Venables & Smith"))
books
books <- data.frame(
name = I(c("Tukey", "Venables", "Tierney",
"Ripley", "Ripley", "McNeil", "R Core")),
title = c("Exploratory Data Analysis",
"Modern Applied Statistics ...",
"LISP-STAT",
"Spatial Statistics", "Stochastic Simulation",
"Interactive Data Analysis",
"An Introduction to R"),
other.author = c(NA, "Ripley", NA, NA, NA, NA,
"Venables & Smith"))
books
(m1 <- merge(authors, books, by.x = "surname", by.y = "name"))
merge(authors, books, by.x = "surname", by.y = "name", all = TRUE)
(m2 <- merge(books, authors, by.x = "name", by.y = "surname"))
stopifnot(as.character(m1[, 1]) == as.character(m2[, 1]),
all.equal(m1[, -1], m2[, -1][ names(m1)[-1] ]),
dim(merge(m1, m2, by = integer(0))) == c(36, 10))
x <- data.frame(k1 = c(NA,NA,3,4,5), k2 = c(1,NA,NA,4,5), data = 1:5)
y <- data.frame(k1 = c(NA,2,NA,4,5), k2 = c(NA,NA,3,4,5), data = 1:5)
merge(x, y, by = c("k1","k2")) # NA's match
merge(x, y, by = "k1") # NA's match, so 6 rows
merge(x, y, by = "k2", incomparables = NA) # 2 rows
x <- data.frame(k1 = c(NA,NA,3,4,5), k2 = c(1,NA,NA,4,5), data = 1:5)
y <- data.frame(k1 = c(NA,2,NA,4,5), k2 = c(NA,NA,3,4,5), data = 1:5)
x
y
merge(x, y, by = c("k1","k2")) # NA's match
merge(x, y, by = "k1") # NA's match, so 6 rows
merge(x, y, by = "k2", incomparables = NA) # 2 rows
Age <- c(22, 25, 26)
Weight <- c(150, 165, 120)
Sex <- c('M', 'M', 'F')
df <- data.frame
df <- data.frame(Age, Weight, Sex, nrow=3)
df
df <- data.frame(Age, Weight, Sex)
df
rownames(df) <- c('Sam', 'Frank', 'Amy')
df
is.data.frame(mtcars)
mat <- matrix(1:25, nrow = 5)
mat
df <- as.data.frame(mat)
df
df <- mtcars
df
head(df)
mean(df$mpg)
head(df,2)
df['mpg']
df[,'mpg']
mean(df['mpg'])
df['mpg']
mean(df['mpg'])
mean(df[,'mpg'])
df[(df$cyl)==6]
df[(df$cyl==6)]
df$cyl==6
df[df$cyl==6,]
subset(df, cyl=6)
subset(df, cyl==66)
subset(df, cyl==6)
subset(df, cyl==6, gear==4)
subset(df, cyl==6, gear==4)
subset(df, cyl==6)
subset(df, cyl==6, gear==3)
df['am', 'gear', 'carb']
df[,c('am', 'gear', 'carb')]
df$performance <- hp/wt
df$performance <- df['hp']/df['wt']
df
df$performance
install.packages('readxl')
library(readxl)
install.packages('xlsx',repos="http://cran.rstudio.com/")
library(xlsx)
library(xlsx)
library("rJava", lib.loc="~/R/win-library/3.4")
library("rJava", lib.loc="~/R/win-library/3.4")
install.packages('xlsx')
install.packages('rjava')
install.packages('rJava')
library(xlsx)
library("rJava", lib.loc="~/R/win-library/3.4")
library("rlang", lib.loc="~/R/win-library/3.4")
detach("package:rlang", unload=TRUE)
detach("package:rJava", unload=TRUE)
install.packages("RODBC")
tf <- c(TRUE,FALSE)
tt <- c(TRUE,TRUE)
ft <- c(FALSE, TRUE)
tt || ft
tt && ft
ft || ft
tf || tf
install.packages('tidyr')
install.packages('data.table')
data1$Click <- data.frame(replicate(1,sample(0:1,1000,rep=TRUE)))
Click <- data.frame(replicate(1,sample(0:1,1000,rep=TRUE)))
View(Click)
help(sample)
install.packages(RevoScaleR)
install.packages("RevoScaleR")
help(RevoScaleR)
library(RevoScaleR)
install.packages("RevoScaleR")
install.packages("glm")
library(glm)
library("glm")
install.packages("glm2")
library("glm2", lib.loc="~/R/win-library/3.4")
letters <- c( "a", "a", "b", "c", "d", "e", "f", "g", "h", "b", "b" )
dummy( as.character(letters) )
install.packages(dummy)
install.packages("dummy")
library("dummy", lib.loc="~/R/win-library/3.4")
letters <- c( "a", "a", "b", "c", "d", "e", "f", "g", "h", "b", "b" )
dummy( as.character(letters) )
letters <- c( "a", "a", "b", "c", "d", "e", "f", "g", "h", "b", "b" )
)
dummy(letters)
help(dummy)
(traindata <- data.frame(var1=as.factor(c("a","b","b","c")),
var2=as.factor(c(1,1,2,3)),
var3=c("val1","val2","val3","val3"),
stringsAsFactors=FALSE))
View(traindata)
dummies_train <- dummy(x=traindata)
View(dummies_train)
setwd('C:/Users/Vincent/Desktop/Data Mining Techniques/Assignment2_DMT')
library("dplyr")
library("data.table")
data_train <- data.table::fread(input = "./Data Mining VU data/training_set_VU_DM_2014.csv",drop = 1)
data_train[data_train == "NULL"] <- NA
#load data
#data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
data <- sample_n(data_train, 500000)
missing_percentage <- apply(data, 2, function(col) sum(is.na(col))/length(col))
missing_percentage
#This will give 34 variables
keep <- names(missing_percentage[missing_percentage<0.8])
keep
data_ver2 <- subset(data, select = keep)
data$prop_log_historical_price
is.na(data$prop_log_historical_price)
sum(is.na(data$prop_log_historical_price))
price_nonzero <- data_train$prop_log_historical_price[data_train$prop_log_historical_price!=0]
range(price_nonzero)
hist(price_nonzero)
range(exp(price_nonzero))
hist(exp(price_nonzero))
hist(exp(data_train$prop_log_historical_price))
#load data
#data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
data <- sample_n(data_train, 500000)
##Visitor historical booking information: visitor_hist_adr_usd, visitor_hist_starrating
#--> visitor_hist_adr_usd, fill NA with median (95%)
#--> visitor_hist_starrating, fill NA with median (95%)
#--> create dummy variable indicating whether a visitor had a previous booking
data$visitor_hist_dummy <- ifelse(is.na(visitor_hist_adr_usd), 1, 0)
##Visitor historical booking information: visitor_hist_adr_usd, visitor_hist_starrating
#--> visitor_hist_adr_usd, fill NA with median (95%)
#--> visitor_hist_starrating, fill NA with median (95%)
#--> create dummy variable indicating whether a visitor had a previous booking
data$visitor_hist_dummy <- ifelse(is.na(data$visitor_hist_adr_usd), 1, 0)
data$visitor_hist_adr_usd[is.na(data$visitor_hist_adr_usd)] <- median(data$visitor_hist_adr_usd[!is.na(data$visitor_hist_adr_usd)])
data$visitor_hist_starrating[is.na(data$visitor_hist_starrating)] <- median(data$visitor_hist_starrating[!is.na(data$visitor_hist_starrating)])
##Property information: prop_starrating, prop_review_score, prop_brand_bool, prop_location_score1, prop_location_score2
#--> prop_starrating, no preprocessing/cleaning needed
#--> prop_review_score, 7364 NA values (0.15%) replaced with median
#--> prop_brand_bool, no preprocessing/cleaning needed
#--> prop_location_score1, no preprocessing/cleaning needed (what to do with skewed data?)
#--> prop_location_score2, 22% NA --> fill with median
data$prop_review_score[is.na(data$prop_review_score)] <- median(data$prop_review_score[!is.na(data$prop_review_score)])
data$prop_location_score2[is.na(data$prop_location_score2)] <- median(data$prop_location_score2[!is.na(data$prop_location_score2)])
##Price information: promotion_flag, prop_log_historical_price
#--> promotion_flag, no preprocessing/cleaning needed
#--> prop_log_historical_price, 14% zeros --> fill with median
data$prop_log_hist_price_dummy <- ifelse(data$prop_log_historical_price==0, 1, 0)
data$prop_log_historical_price[data$prop_log_historical_price==0] <- median(data$prop_log_historical_price[data$prop_log_historical_price!=0])
missing_percentage <- apply(data, 2, function(col) sum(is.na(col))/length(col))
#This will give 34 variables
keep <- names(missing_percentage[missing_percentage<0.8])
data_ver2 <- subset(data, select = keep)
keep_id <- unique(data_ver2$srch_id)
#split data random into train and test
dt <- sample(keep_id, train_instances*length(keep_id))
train_instances<-0.8
#split data random into train and test
dt <- sample(keep_id, train_instances*length(keep_id))
train <- subset(data_ver2, srch_id %in% dt)
test <- subset(data_ver2, !(srch_id %in% dt))
keep_id <- unique(data_ver2$srch_id)
data_train <- data.table::fread(input = "./Data Mining VU data/training_set_VU_DM_2014.csv")
data_train[data_train == "NULL"] <- NA
#load data
#data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
data <- sample_n(data_train, 500000)
##Visitor historical booking information: visitor_hist_adr_usd, visitor_hist_starrating
#--> visitor_hist_adr_usd, fill NA with median (95%)
#--> visitor_hist_starrating, fill NA with median (95%)
#--> create dummy variable indicating whether a visitor had a previous booking
data$visitor_hist_dummy <- ifelse(is.na(data$visitor_hist_adr_usd), 1, 0)
data$visitor_hist_adr_usd[is.na(data$visitor_hist_adr_usd)] <- median(data$visitor_hist_adr_usd[!is.na(data$visitor_hist_adr_usd)])
data$visitor_hist_starrating[is.na(data$visitor_hist_starrating)] <- median(data$visitor_hist_starrating[!is.na(data$visitor_hist_starrating)])
##Property information: prop_starrating, prop_review_score, prop_brand_bool, prop_location_score1, prop_location_score2
#--> prop_starrating, no preprocessing/cleaning needed
#--> prop_review_score, 7364 NA values (0.15%) replaced with median
#--> prop_brand_bool, no preprocessing/cleaning needed
#--> prop_location_score1, no preprocessing/cleaning needed (what to do with skewed data?)
#--> prop_location_score2, 22% NA --> fill with median
data$prop_review_score[is.na(data$prop_review_score)] <- median(data$prop_review_score[!is.na(data$prop_review_score)])
data$prop_location_score2[is.na(data$prop_location_score2)] <- median(data$prop_location_score2[!is.na(data$prop_location_score2)])
##Price information: promotion_flag, prop_log_historical_price
#--> promotion_flag, no preprocessing/cleaning needed
#--> prop_log_historical_price, 14% zeros --> fill with median
data$prop_log_hist_price_dummy <- ifelse(data$prop_log_historical_price==0, 1, 0)
data$prop_log_historical_price[data$prop_log_historical_price==0] <- median(data$prop_log_historical_price[data$prop_log_historical_price!=0])
missing_percentage <- apply(data, 2, function(col) sum(is.na(col))/length(col))
#This will give 34 variables
keep <- names(missing_percentage[missing_percentage<0.8])
data_ver2 <- subset(data, select = keep)
keep_id <- unique(data_ver2$srch_id)
#split data random into train and test
dt <- sample(keep_id, train_instances*length(keep_id))
#load data
#data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
data <- sample_n(data_train, 500000)
data$visitor_hist_adr_usd
##Visitor historical booking information: visitor_hist_adr_usd, visitor_hist_starrating
#--> visitor_hist_adr_usd, fill NA with median (95%)
#--> visitor_hist_starrating, fill NA with median (95%)
#--> create dummy variable indicating whether a visitor had a previous booking
data$visitor_hist_adr_usd <- sapply(data$visitor_hist_adr_usd, as.numeric)
data$visitor_hist_dummy <- ifelse(is.na(data$visitor_hist_adr_usd), 1, 0)
data$visitor_hist_adr_usd[is.na(data$visitor_hist_adr_usd)] <- median(data$visitor_hist_adr_usd[!is.na(data$visitor_hist_adr_usd)])
data$visitor_hist_starrating[is.na(data$visitor_hist_starrating)] <- median(data$visitor_hist_starrating[!is.na(data$visitor_hist_starrating)])
data$visitor_hist_starrating
data$visitor_hist_starrating <- sapply(data$visitor_hist_starrating, as.numeric)
#load data
#data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
data <- sample_n(data_train, 500000)
##Visitor historical booking information: visitor_hist_adr_usd, visitor_hist_starrating
#--> visitor_hist_adr_usd, fill NA with median (95%)
#--> visitor_hist_starrating, fill NA with median (95%)
#--> create dummy variable indicating whether a visitor had a previous booking
data$visitor_hist_adr_usd <- sapply(data$visitor_hist_adr_usd, as.numeric)
data$visitor_hist_starrating <- sapply(data$visitor_hist_starrating, as.numeric)
data$visitor_hist_dummy <- ifelse(is.na(data$visitor_hist_adr_usd), 1, 0)
data$visitor_hist_adr_usd[is.na(data$visitor_hist_adr_usd)] <- median(data$visitor_hist_adr_usd[!is.na(data$visitor_hist_adr_usd)])
data$visitor_hist_starrating[is.na(data$visitor_hist_starrating)] <- median(data$visitor_hist_starrating[!is.na(data$visitor_hist_starrating)])
##Property information: prop_starrating, prop_review_score, prop_brand_bool, prop_location_score1, prop_location_score2
#--> prop_starrating, no preprocessing/cleaning needed
#--> prop_review_score, 7364 NA values (0.15%) replaced with median
#--> prop_brand_bool, no preprocessing/cleaning needed
#--> prop_location_score1, no preprocessing/cleaning needed (what to do with skewed data?)
#--> prop_location_score2, 22% NA --> fill with median
data$prop_review_score <- sapply(data$prop_review_score, as.numeric)
data$prop_location_score2 <- sapply(data$prop_location_score2, as.numeric)
data$prop_review_score[is.na(data$prop_review_score)] <- median(data$prop_review_score[!is.na(data$prop_review_score)])
data$prop_location_score2[is.na(data$prop_location_score2)] <- median(data$prop_location_score2[!is.na(data$prop_location_score2)])
##Price information: promotion_flag, prop_log_historical_price
#--> promotion_flag, no preprocessing/cleaning needed
#--> prop_log_historical_price, 14% zeros --> fill with median
data$prop_log_hist_price_dummy <- ifelse(data$prop_log_historical_price==0, 1, 0)
data$prop_log_historical_price[data$prop_log_historical_price==0] <- median(data$prop_log_historical_price[data$prop_log_historical_price!=0])
missing_percentage <- apply(data, 2, function(col) sum(is.na(col))/length(col))
#This will give 34 variables
keep <- names(missing_percentage[missing_percentage<0.8])
data_ver2 <- subset(data, select = keep)
keep_id <- unique(data_ver2$srch_id)
data_ver2$srch_id
#split data random into train and test
dt <- sample(keep_id, train_instances*length(keep_id))
train <- subset(data_ver2, srch_id %in% dt)
test <- subset(data_ver2, !(srch_id %in% dt))
colnames(data_ver2)
#split data into numerical and nominal values (check this!)
num <- train[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_length_of_stay","srch_booking_window","srch_adults_count","srch_children_count",
"srch_room_count","orig_destination_distance")]
nom <- train[,c("srch_id", "site_id", "visitor_location_country_id", "prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "srch_saturday_night_bool", "random_bool",
"comp2_rate", "comp2_inv", "comp3_rate", "comp3_inv", "comp5_rate", "comp5_inv", "comp8_rate", "comp8_inv")]
num_median <- apply(num, 2, function(x) median(x, na.rm = TRUE))
nom_occur <- apply(nom, 2, function(x) names(which.max(table(x))))
numeric_median <- function(x, num_median){
for(i in 1:length(x[1,])){
x[,i][is.na(x[,i])] <- unname(num_median[i])
}
return(x)
}
nominal_occurence <- function(x, nom_occur){
for(i in 1:length(x[1,])){
x[,i][is.na(x[,i])] <- unname(nom_occur[i])
}
return(x)
}
num <- numeric_median(num, num_median)
colnames(data_ver2)
#Drop certain variables: date_time, site_id, visitor_location_country_id, prop_country_id, prop_id, price_usd,
data_ver2$date_time <- NULL
data_ver2$site_id <- NULL
data_ver2$visitor_location_country_id <- NULL
data_ver2$prop_country_id <- NULL
data_ver2$prop_id <- NULL
data_ver2$price_usd <- NULL
colnames(data_ver2)
data_ver2$comp2_inv
sum(is.na(data_ver2$comp2_inv))
sum(is.na(data_ver2$comp2_inv))/nrow(data_ver2)
missing_percentage
keep <- names(missing_percentage[missing_percentage<0.5])
data_ver2 <- subset(data, select = keep)
#Drop variables with low relevance/quality: date_time, site_id, visitor_location_country_id, prop_country_id, prop_id, price_usd,
data_ver2$date_time <- NULL
data_ver2$site_id <- NULL
data_ver2$prop_country_id <- NULL
data_ver2$visitor_location_country_id <- NULL
data_ver2$prop_id <- NULL
data_ver2$price_usd <- NULL #low quality due to different meaning/currency per country..
#split data random into train and test
keep_id <- unique(data_ver2$srch_id)
dt <- sample(keep_id, train_instances*length(keep_id))
train <- subset(data_ver2, srch_id %in% dt)
test <- subset(data_ver2, !(srch_id %in% dt))
colnames(data_ver2)
missing_percentage<0.5
missing_percentage[missing_percentage<0.5]
data$orig_destination_distance
sum(data$orig_destination_distance=="0")
data$orig_destination_distance <- sapply(data$orig_destination_distance, as.numeric)
data$orig_destination_distance
hist(data$orig_destination_distance)
#give relevance scores (clicked -> 1, booked -> 5 and other -> 0)
target <- train$booking_bool + train$click_bool
target[target==2] <- 5
train_set <- cbind(num, nom, target)
train
colnames(train)
#give relevance scores (clicked -> 1, booked -> 5 and other -> 0)
target <- train$booking_bool + train$click_bool
target[target==2] <- 5
train$click_bool <- NULL
train$booking_bool <- NULL
train_set <- cbind(num, nom, target)
train_set <- cbind(train, target)
colnames(train_set)
#load data
#data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
data <- sample_n(data_train, 500000)
##Visitor historical booking information: visitor_hist_adr_usd, visitor_hist_starrating
#--> visitor_hist_adr_usd, fill NA with median (95%)
#--> visitor_hist_starrating, fill NA with median (95%)
#--> create dummy variable indicating whether a visitor had a previous booking
data$visitor_hist_adr_usd <- sapply(data$visitor_hist_adr_usd, as.numeric)
data$visitor_hist_starrating <- sapply(data$visitor_hist_starrating, as.numeric)
data$visitor_hist_dummy <- ifelse(is.na(data$visitor_hist_adr_usd), 1, 0)
data$visitor_hist_adr_usd[is.na(data$visitor_hist_adr_usd)] <- median(data$visitor_hist_adr_usd[!is.na(data$visitor_hist_adr_usd)])
data$visitor_hist_starrating[is.na(data$visitor_hist_starrating)] <- median(data$visitor_hist_starrating[!is.na(data$visitor_hist_starrating)])
##Property information: prop_starrating, prop_review_score, prop_brand_bool, prop_location_score1, prop_location_score2
#--> prop_starrating, no preprocessing/cleaning needed
#--> prop_review_score, 7364 NA values (0.15%) replaced with median
#--> prop_brand_bool, no preprocessing/cleaning needed
#--> prop_location_score1, no preprocessing/cleaning needed (what to do with skewed data?)
#--> prop_location_score2, 22% NA --> fill with median
data$prop_review_score <- sapply(data$prop_review_score, as.numeric)
data$prop_location_score2 <- sapply(data$prop_location_score2, as.numeric)
data$prop_review_score[is.na(data$prop_review_score)] <- median(data$prop_review_score[!is.na(data$prop_review_score)])
data$prop_location_score2[is.na(data$prop_location_score2)] <- median(data$prop_location_score2[!is.na(data$prop_location_score2)])
##Price information: promotion_flag, prop_log_historical_price
#--> promotion_flag, no preprocessing/cleaning needed
#--> prop_log_historical_price, 14% zeros --> fill with median
#--> create dummy variable indicating if hotel has an historical booking
data$prop_log_hist_price_dummy <- ifelse(data$prop_log_historical_price==0, 1, 0)
data$prop_log_historical_price[data$prop_log_historical_price==0] <- median(data$prop_log_historical_price[data$prop_log_historical_price!=0])
#Skip variables with many NA values --> 34 variables left
missing_percentage <- apply(data, 2, function(col) sum(is.na(col))/length(col))
keep <- names(missing_percentage[missing_percentage<0.5])
data_ver2 <- subset(data, select = keep)
#Drop variables with low relevance/quality: date_time, site_id, visitor_location_country_id, prop_country_id, prop_id, price_usd,
data_ver2$date_time <- NULL
data_ver2$site_id <- NULL
data_ver2$visitor_location_country_id <- NULL
data_ver2$prop_country_id <- NULL
data_ver2$prop_id <- NULL
data_ver2$price_usd <- NULL #low quality due to different meaning/currency per country..
data_ver2$orig_destination_distance <- NULL #low quality, many zeros and NA values..
#split data random into train and test
keep_id <- unique(data_ver2$srch_id)
dt <- sample(keep_id, train_instances*length(keep_id))
train <- subset(data_ver2, srch_id %in% dt)
test <- subset(data_ver2, !(srch_id %in% dt))
#give relevance scores (clicked -> 1, booked -> 5 and other -> 0)
target <- train$booking_bool + train$click_bool
target[target==2] <- 5
train$click_bool <- NULL
train$booking_bool <- NULL
train_set <- cbind(train, target)
#give relevance scores (clicked -> 1, booked -> 5 and other -> 0)
target <- test$booking_bool + test$click_bool
target[target==2] <- 5
test$click_bool <- NULL
test$booking_bool <- NULL
test_set <- cbind(test, target)
out <- list()
out$train <- train_set
out$test <- test_set
#load data
#data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
data <- sample_n(data_train, 500000)
#preprocess data
source("data_scripts_v2/iteration8_v2.R")
#preprocess data
setwd("C:/Users/Vincent/Documents/GitHub/Assignment2/data_scripts_v2")
source("data_scripts_v2/iteration8_v2.R")
#preprocess data
setwd("C:/Users/Vincent/Documents/GitHub/Assignment2")
source("data_scripts_v2/iteration8_v2.R")
data_new <- iteration8_v2(data, 0.8)
train
train[, -("srch_room_count")]
ncol(train[, -("srch_room_count")])
ncol(train)
#train xgboost
library(xgboost)
install.packages("xgboost")
#train xgboost
library(xgboost)
train <- data_new$train[order(data_new$train$srch_id),]
counts <- data.frame(table(data_new$train$srch_id))
counts
dtrain <- xgb.DMatrix(as.matrix(train[,-c("srch_id", "target")]), label = train$target, group = counts$Freq) #without srch_id, target
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c("srch_id", "target")]))
#listwise model (lambdaMart)
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
#calculate variable importance and create graph
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
#Calculate NDCG
predictions <- predict(bst,dtest)
id <- data_new$test$srch_id
label <- data_new$test$target
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
metric
predictions
id
label
is.na(id)
sum(is.na(id))
sum(is.na(label))
sum(is.na(predictions))
metric <- ndcg(label, id, predictions, 38)
metric <- ndcg(label, id, predictions, 38)
metric <- ndcg(label, id, predictions, 38)
metric <- ndcg(label, id, predictions, 38)
metric <- ndcg(label, id, predictions, 38)
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
ndcg
metric <- ndcg(label, id, predictions, 20)
metric <- ndcg(label, id, predictions, 2)
metric <- ndcg(label, id, predictions, 38)
predictions

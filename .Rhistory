?min_rank
transmute(flight, new = air_time - dep_time)
transmute(flights, new = air_time - dep_time)
1:3
1:3 + 1:10
summarise(flights, delya = mean(dep_delay, na.rm = TRUE))
summarise(flights)
by_dest <- group_by(flights, dest)
by_dest
by_dest <- group_by(flights, dest)
delay <- summarise(by_dest,
count = n(),
dist = mean(distance, na.rm = TRUE),
delay = mean(arr_delay, na.rm = TRUE)
)
delay <- filter(delay, count > 20, dest != "HNL")
delay
by_dest <- group_by(flights, dest)
delay <- summarise(by_dest,
count = n(),
dist = mean(distance, na.rm = TRUE),
delay = mean(arr_delay, na.rm = TRUE)
)
delay
?n()
flights %/% group_by(year, month, day) %/% summarise(mean = mean(dep_delay))
flights %>% group_by(year, month, day) %>% summarise(mean = mean(dep_delay))
flights %>% group_by(year, month, day) %>% summarise(mean = mean(dep_delay, na.rm = T))
not_cancelled <- flights %>% filter(!is.na(dep_delay), !is.na(arr_delay)) %>% summarise(mean = mean(dep_delay))
not_cancelled
not_cancelled <- flights %>% filter(!is.na(dep_delay), !is.na(arr_delay)) %>% group_by(year, month, day) %>% summarise(mean = mean(dep_delay))
not_cancelled
group_by(not_cancelled, tailnum)
not_cancelled %>% group_by(tailnum)
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>%
group_by(year, month, day) %>%
summarise(mean = mean(dep_delay))
delays <- not_cancelled %>%
group_by(tailnum) %>%
summarise(
delay = mean(arr_delay)
)
delays
not_cancelled
not_cancelled <- flights %>% filter(!is.na(dep_delay), !is.na(arr_delay)) %>% group_by(year, month, day) %>% summarise(mean = mean(dep_delay))
not_cancelled
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>%
group_by(year, month, day) %>%
summarise(mean = mean(dep_delay))
not_cancelled %>% group_by(tailnum)
not_cancelled
not_cancelled %>%
group_by(year, month, day) %>%
summarise(hour_perc = mean(arr_delay > 60))
not_cancelled
?glimpse
not_cancelled %>%
group_by(year, month, day) %>%
summarise(mean = mean(dep_delay))
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
source('~/visualisation.R')
ggplot(data = mpg) + geom_point(mapping = aes(x = displ , y = hwy ))
source('~/visualisation.R')
library(tidyverse)
dat  <-  gapminder
library(gapminder)
install.packages("gapminder")
library(gapminder)
dat <- gapminder
View(gapminder)
?gapminder
head(gapminder)
typeof(gapminder)
library(tidyverse)
?rnorm
df <- tibble(x = rnorm(100,3,5), y = rnorm(100,10,5))
df
df <-tibble( x = rnorm(100,3,5), y = rnorm(100,10,5))
(df <-tibble( x = rnorm(100,3,5), y = rnorm(100,10,5)))
colnum(df)
?col_number
col_number(df)
dim(df)
?seq
rep(1,10)
rep(1,10) + zeros(1,10)
rep(1,10) + rep(1,10)
library(tidyverse)
head(diamonds)
ggplot(data  = diamonds) + geom_boxplot(mapping = aes(x = cut, y = count()))
ggplot(data  = diamonds) + geom_boxplot(mapping = aes(x = cut, y = count)
)
ggplot(data  = diamonds) + geom_boxplot(mapping = aes(x = cut, y = carat))
diamond <- diamonds
mutate(diamond, countCut = count(cut))
diamonds %>% count(cut)
ggplot(data = diamond) + geom_histogram(mapping = aes(x = depth), binwidth = 0.5)
?wilcoxon.test
?wilcox.test()
diamond&depth
select(diamond, depth)
wilcox.test(select(diamond, depth))
typeof(select(diamond,depth))
x <- as.data.frame(select(diamond,depth))
typeof(x)
head(x)
wilcox.test(x)
class(as.data.frame(select(diamond, depth)))
x <- as.data.frame(select(diamond, depth))
head(x)
class(x)
typeof(x)
?shapiro.test()
shapiro.test(select(diamond, depth))
shapiro.test(as.data.frame(select(diamond,depth)))
shapiro.test(x)
is.numeric(x)
head(x)
class(x)
colnames(x)
?for
()
?for()
?map()
library(gapminder)
head(gapminder)
?round
?arrange
gapminder %>% arrange(gdpPercap)
gapminder %>% arrange(desc(gdpPercap))
gapminder %>% arrange(desc(gdpPercap), desc(pop))
gapminder %>% arrange(desc(pop))
?filter
gapminder %>% filter(country == "Netherlands")
gapminder %>% filter(country == "Netherlands") %>% arrange(year)
dutchData <- gapminder %>% filter(country == "Netherlands") %>% arrange(year)
dutchData
ggplot(data = dutchData) + geom_bar(mapping = aes(x = year, y = lifeExp))
ggplot(data = dutchData) + geom_histogram(mapping = aes(x = year, y = lifeExp))
ggplot(data = dutchData) + geom_plot(mapping = aes(x = year, y = lifeExp))
?ggplot2
ggplot(data = dutchData) + geom_line(mapping = aes(x = year, y = lifeExp))
NotFilterdutchData <- gapminder %>% filter(country == "Netherlands")
ggplot(data = NotFilterdutchData) + geom_line(mapping = aes(x = year, y = lifeExp))
Europe <- gapminder %>% filter(continent == "Europe")
ggplot(data = Europe) + geom_line(mapping = aes(x = year, y = lifeExp, colour = continent))
ggplot(data = Europe) + geom_line(mapping = aes(x = year, y = lifeExp, colour = country))
gapminder %>% filter(country == "Turkey")
gapminder %>% arrange(lifeExp)
gapminder %>% filter(year == 2007) %>% arrange(desc(lifeExp))
lifExp2007 <- gapminder %>% filter(year == 2007) %>% arrange(desc(lifeExp))
View(lifeExp2007)
View(lifExp2007)
lifExp2007 <- gapminder %>% filter(year == 2007) %>% arrange(desc(lifeExp)) %>% select(country, lifeExp)
?mutate
new <- gapminder %>% mutate(totalGdp = pop * gdpPercap)
new
new <- gapminder %>% mutate(totalGdp = pop * gdpPercap) %>% arrange(desc(totalGdp))
new
new <- gapminder %>% mutate(totalGdp = pop * gdpPercap) %>% filter(year == 2007) %>% arrange(desc(totalGdp))
new
new <- gapminder %>% mutate(totalGdp = pop * gdpPercap) %>% filter(year == 2007, continent == "Europe") %>% arrange(desc(totalGdp))
new
?signif
signif(1000,2)
signif(1000,2)/1000
library(modelr)
?bootstrap
mod <- lm(log(price) ~ log(carat), data = diamonds)
mod
summary(mod)
diamonds
diamonds %>%
mutate(lgprice = log(price), lgCarat = log(carat))
diamonds %>%
mutate(lgprice = log(price), lgCarat = log(carat)) %>%
select(lgprice, lgCarat)
diamonds %>%
mutate(lgprice = log(price), lgCarat = log(carat)) %>%
select(lgprice, lgCarat) %>%
ggplot() + geom_point(mapping = aes(x = lgprice, y = lgCarat))
tfData <- diamonds %>%
mutate(lgprice = log(price), lgCarat = log(carat)) %>%
select(lgprice, lgCarat)
tfData %>%
ggplot() + geom_point(mapping = aes(x = lgprice, y = lgCarat))
tfData
tfData %>%
lm(lgpric ~ lgCarat)
diamonds %>% lm(price ~ carat)
mod <- lm(lgprice ~ lgCarat, data = tfData)
diamonds %>% ggplot() + geom_point(mapping = aes(x = price, y = carat))
1/71
0.01408451*3600
3600/71
-1/(4*3600/71(1-40/(4*3600/71))) * log(0.99)
log(0.99)
-1/(4*3600/71(1-40/(4*3600/71)))
-1/(4*3600/71*(1-40/(4*3600/71))) * log(0.99)
1-6.172784e-05
?pnorm
qnorm(5/9,20,1)
qnorm(5/9,20,2)
qnorm(4/9,20,1)
qnorm(4/9,20,2)
?rpois
ppois(0.975,lambda = 200)
qpois(0.975,lambda = 200)
qpois(0.025,lambda = 200)
?qnorm
qnorm(5/9-20)
qnorm(5/9)
qnorm(5/9) + 20
qnorm(5/9)*sqrt(2) + 20
load("lda_user.rda")
?dist
jaccard.index(1:10, 2:20)
library(text2vec)
sim2(1:10,2:20, method = "cosine")
B = matrix(
c(2, 4, 3, 1, 5, 7),
nrow=3,
ncol=2)
C <- t(B)
sim2(B,C, method = "cosine")
x<-rnorm(10)
x<-matrix(x)
y<-matrix(rnorm(10*5),nrow=5)
x
y
install.packages("shiny")
install.packages("Shines")
install.packages("shinyjs")
install.packages("DT")
library(data.table)
data <- data.table::fread(input = "../dataset_mood_smartphone.csv",drop = 1)
setwd("~/Desktop/Assignment2")
library(data.table)
data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"))
head(data, n=10)
missing_percentage <- apply(data, 2, function(col) sum(is.na(col))/length(col))
hist(missing_percentage)
sum(missing_percentage>=0.8)
names(missing_percentage[missing_percentage>=0.8])
keep <- names(missing_percentage[missing_percentage<0.8])
data_ver2 <- subset(data, select = keep)
keep
missing_percentage
colnames(data)
num <- data_ver2[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_length_of_stay","srch_booking_window","srch_adults_count","srch_children_count",
"srch_room_count","orig_destination_distance", "position")]
nom <- data_ver2[,c("srch_id", "site_id", "visitor_location_country_id", "prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "srch_saturday_night_bool", "random_bool",
"comp2_rate", "comp2_inv", "comp3_rate", "comp3_inv", "comp5_rate", "comp5_inv", "comp8_rate", "comp8_inv")]
myNum <- function(x){
x[is.na(x)] <- median(x, na.rm = TRUE)
x
}
myNom <- function(x){
x[is.na(x)] <- names(which.max(table(x)))
x
}
num2 <- num[, lapply(.SD, myNum)]
nom2 <- nom[, lapply(.SD, myNom)]
nom2 <- as.data.frame(lapply(nom2, function(x) as.numeric(as.character(x))))
date_time <- as.Date(data_ver2$date_time)
X <- cbind(num2, nom2, date_time)
colnames(X)
cor(X)
cor(X[,c("price_usd", "position", "prop_id", "srch_destination_id")])
head(date_time)
head(month(date_time))
a <- head(month(date_time))
X <- cbind(num2, nom2, month(date_time))
cor(X[,c("price_usd", "position", "prop_id", "srch_destination_id", "V3")])
colnames(X)
unique(X$srch_id)
length(unique(X$srch_id))
colnames(X)
positionmean <- with(X, unlist(tapply(position, srch_id, function(x) mean(x))))
head(positionmean)
X <- cbind(num2, nom2, month(date_time), positionmean)
positionmean <- with(X, unlist(tapply(position, srch_id, function(x) x - mean(x))))
positionmean <- positionmean + X$position
X <- cbind(num2, nom2, month(date_time), positionmean)
head(positionmean)
head(positionmean)
positionmean
positionmean <- with(X, unlist(tapply(position, srch_id, function(x) x - mean(x))))
positionmean
positionmean <- with(X, unlist(tapply(position, srch_id, function(x) mean(x) - x)))
positionmean <- positionmean + X$position
positionmean
X <- cbind(num2, nom2, month(date_time), positionmean)
cor(X[,c("price_usd", "position", "prop_id", "srch_destination_id", "V3", positionmean)])
cor(X[,c("price_usd", "position", "prop_id", "srch_destination_id", "V3", "positionmean")])
positionmean <- with(X, unlist(tapply(position, srch_id, function(x) median(x) - x)))
positionmean <- positionmean + X$position
X <- cbind(num2, nom2, month(date_time), positionmean)
cor(X[,c("price_usd", "position", "prop_id", "srch_destination_id", "V3", "positionmean")])
dataset <- X[,c("prop_id", "srch_destination_id", "V3", "positionmean", "position")]
colnames(dataset)
positionmean <- with(X, unlist(tapply(position, prop_id, function(x) median(x) - x)))
positionmean <- positionmean + X$position
X <- cbind(num2, nom2, month(date_time), positionmean)
cor(X[,c("price_usd", "position", "prop_id", "srch_destination_id", "V3", "positionmean")])
dataset <- X[,c("prop_id", "srch_destination_id", "V3", "positionmean", "position")]
nrow(dataset)
dt = sort(sample(nrow(dataset), nrow(dataset)*.8))
dt
dt = sample(nrow(dataset), nrow(dataset)*.8)
dt
sort(Dt)
sort(dt)
dt = sort(sample(nrow(dataset), nrow(dataset)*.8))
dt
train <- dataset[dt,]
test <- dataset[-dt,]
colnames(train)
dtrain <- xgb.DMatrix(as.matrix(train[,-c(4)]), label = train$position)
library(xgboost)
dtrain <- xgb.DMatrix(as.matrix(train[,-c(4)]), label = train$position)
dtest <- xgb.DMatrix(as.matrix(test[,-c(4)]), label = train$position)
dtest <- xgb.DMatrix(as.matrix(test[,-c(4)]), label = test$position)
bst <- xgb.cv(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "reg:linear",
nfold=5,verbose = 3, eval_metric = "rmse")
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 8, objective = "reg:linear",
nfold=5,verbose = 3, eval_metric = "rmse")
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
head(train)
head(as.matrix(train[,-c(4)]))
predictions <- predict(bst,dtest)
predictions
(predictions - test$position)^2
sum((predictions - test$position)^2)/(length(predictions))
length(unique(X$prop_id))
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 20, objective = "reg:linear",
nfold=5,verbose = 3, eval_metric = "rmse")
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "reg:linear",
nfold=5,verbose = 3, eval_metric = "rmse")
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
positionmean <- with(X, unlist(tapply(position, prop_id, function(x) median(x))))
positionmedian <- with(X, unlist(tapply(position, prop_id, function(x) median(x))))
positionmedian <- with(X, unlist(tapply(position, prop_id, function(x) median(x))))
positionmedian <- with(X, unlist(tapply(position, prop_id, function(x) median(x) - x)))
positionmedian <- positionmean + X$position
positionmedian <- positionmedian + X$position
head(positionmedian)
head(X)
positionmedian
positionmedian <- with(X, unlist(tapply(position, prop_id, function(x) median(x))))
?tapply
positionmedian <- with(X, tapply(position, prop_id, function(x) median(x)))
head(positionmedian)
positionmedian
key <- data.frame(positionmedian, id = names(positionmedian))
head(key)
key <- data.frame(median_postition = positionmedian, id = names(positionmedian))
X$estimate_position <- key[match(X$prop_id, key$id), "median_postition"]
head(X)
head(positionmedian)
head(names(positionmedian))
head(values(positionmedian))
head(unlist(positionmedian))
head(unname(positionmedian))
key <- data.frame(median_postition = unname(positionmedian), id = names(positionmedian))
X$estimate_position <- key[match(X$prop_id, key$id), "median_postition"]
head(X)
head(positionmedian)
unique(X$prop_id)
length(unique(X$prop_id))
data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"))
head(data, n=10)
missing_percentage <- apply(data, 2, function(col) sum(is.na(col))/length(col))
hist(missing_percentage)
sum(missing_percentage>=0.8)
names(missing_percentage[missing_percentage>=0.8])
keep <- names(missing_percentage[missing_percentage<0.8])
data_ver2 <- subset(data, select = keep)
num <- data_ver2[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_length_of_stay","srch_booking_window","srch_adults_count","srch_children_count",
"srch_room_count","orig_destination_distance")]
nom <- data_ver2[,c("srch_id", "site_id", "visitor_location_country_id", "prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "srch_saturday_night_bool", "random_bool",
"comp2_rate", "comp2_inv", "comp3_rate", "comp3_inv", "comp5_rate", "comp5_inv", "comp8_rate", "comp8_inv")]
myNum <- function(x){
x[is.na(x)] <- median(x, na.rm = TRUE)
x
}
myNom <- function(x){
x[is.na(x)] <- names(which.max(table(x)))
x
}
num2 <- num[, lapply(.SD, myNum)]
nom2 <- nom[, lapply(.SD, myNom)]
nom2 <- as.data.frame(lapply(nom2, function(x) as.numeric(as.character(x))))
date_time <- as.Date(data_ver2$date_time)
target <- data_ver2$booking_bool + data_ver2$click_bool
target[target==2] <- 5
hist(target)
X <- cbind(num2, nom2, target)
X$estimate_position <- key[match(X$prop_id, key$id), "median_postition"]
new_X <- X
keep_id <- unique(X$srch_id)
library(xgboost)
dt <- sample(keep_id, 0.8*length(keep_id))
train <- subset(new_X, srch_id %in% dt)
test <- subset(new_X, !(srch_id %in% dt))
train <- train[order(train$srch_id),]
counts <- data.frame(table(train$srch_id))
colnames(train)
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,31)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(test[,-c(12,31)]))
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
predictions <- predict(bst,dtest)
id <- test$srch_id
label <- test$target
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
metric
dt <- sample(keep_id, 0.8*length(keep_id))
train <- subset(new_X, srch_id %in% dt)
test <- subset(new_X, !(srch_id %in% dt))
train <- train[order(train$srch_id),]
counts <- data.frame(table(train$srch_id))
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,31)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(test[,-c(12,31)]))
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
predictions <- predict(bst,dtest)
id <- test$srch_id
label <- test$target
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
metric
hist(positionmedian)
library(data.table)
data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"))
head(data, n=10)
missing_percentage <- apply(data, 2, function(col) sum(is.na(col))/length(col))
hist(missing_percentage)
sum(missing_percentage>=0.8)
names(missing_percentage[missing_percentage>=0.8])
keep <- names(missing_percentage[missing_percentage<0.8])
data_ver2 <- subset(data, select = keep)
num <- data_ver2[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_length_of_stay","srch_booking_window","srch_adults_count","srch_children_count",
"srch_room_count","orig_destination_distance", "position")]
nom <- data_ver2[,c("srch_id", "site_id", "visitor_location_country_id", "prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "srch_saturday_night_bool", "random_bool",
"comp2_rate", "comp2_inv", "comp3_rate", "comp3_inv", "comp5_rate", "comp5_inv", "comp8_rate", "comp8_inv")]
myNum <- function(x){
x[is.na(x)] <- median(x, na.rm = TRUE)
x
}
myNom <- function(x){
x[is.na(x)] <- names(which.max(table(x)))
x
}
num2 <- num[, lapply(.SD, myNum)]
nom2 <- nom[, lapply(.SD, myNom)]
nom2 <- as.data.frame(lapply(nom2, function(x) as.numeric(as.character(x))))
date_time <- as.Date(data_ver2$date_time)
target <- data_ver2$booking_bool + data_ver2$click_bool
target[target==2] <- 5
hist(target)
X <- cbind(num2, nom2, target)
positionmedian <- with(X, tapply(position, prop_id, function(x) median(x)))
key <- data.frame(median_postition = unname(positionmedian), id = names(positionmedian))
X$estimate_position <- key[match(X$prop_id, key$id), "median_postition"]
X$position <- NULL
new_X <- X
keep_id <- unique(X$srch_id)
library(xgboost)
dt <- sample(keep_id, 0.8*length(keep_id))
train <- subset(new_X, srch_id %in% dt)
test <- subset(new_X, !(srch_id %in% dt))
train <- train[order(train$srch_id),]
counts <- data.frame(table(train$srch_id))
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,31)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(test[,-c(12,31)]))
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 5, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
predictions <- predict(bst,dtest)
id <- test$srch_id
label <- test$target
source("ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
setwd("~/Desktop/Assignment2/Data_scripts")
setwd("~/Desktop/Assignment2")

delay
by_dest <- group_by(flights, dest)
delay <- summarise(by_dest,
count = n(),
dist = mean(distance, na.rm = TRUE),
delay = mean(arr_delay, na.rm = TRUE)
)
delay
?n()
flights %/% group_by(year, month, day) %/% summarise(mean = mean(dep_delay))
flights %>% group_by(year, month, day) %>% summarise(mean = mean(dep_delay))
flights %>% group_by(year, month, day) %>% summarise(mean = mean(dep_delay, na.rm = T))
not_cancelled <- flights %>% filter(!is.na(dep_delay), !is.na(arr_delay)) %>% summarise(mean = mean(dep_delay))
not_cancelled
not_cancelled <- flights %>% filter(!is.na(dep_delay), !is.na(arr_delay)) %>% group_by(year, month, day) %>% summarise(mean = mean(dep_delay))
not_cancelled
group_by(not_cancelled, tailnum)
not_cancelled %>% group_by(tailnum)
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>%
group_by(year, month, day) %>%
summarise(mean = mean(dep_delay))
delays <- not_cancelled %>%
group_by(tailnum) %>%
summarise(
delay = mean(arr_delay)
)
delays
not_cancelled
not_cancelled <- flights %>% filter(!is.na(dep_delay), !is.na(arr_delay)) %>% group_by(year, month, day) %>% summarise(mean = mean(dep_delay))
not_cancelled
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
not_cancelled %>%
group_by(year, month, day) %>%
summarise(mean = mean(dep_delay))
not_cancelled %>% group_by(tailnum)
not_cancelled
not_cancelled %>%
group_by(year, month, day) %>%
summarise(hour_perc = mean(arr_delay > 60))
not_cancelled
?glimpse
not_cancelled %>%
group_by(year, month, day) %>%
summarise(mean = mean(dep_delay))
not_cancelled <- flights %>%
filter(!is.na(dep_delay), !is.na(arr_delay))
source('~/visualisation.R')
ggplot(data = mpg) + geom_point(mapping = aes(x = displ , y = hwy ))
source('~/visualisation.R')
library(tidyverse)
dat  <-  gapminder
library(gapminder)
install.packages("gapminder")
library(gapminder)
dat <- gapminder
View(gapminder)
?gapminder
head(gapminder)
typeof(gapminder)
library(tidyverse)
?rnorm
df <- tibble(x = rnorm(100,3,5), y = rnorm(100,10,5))
df
df <-tibble( x = rnorm(100,3,5), y = rnorm(100,10,5))
(df <-tibble( x = rnorm(100,3,5), y = rnorm(100,10,5)))
colnum(df)
?col_number
col_number(df)
dim(df)
?seq
rep(1,10)
rep(1,10) + zeros(1,10)
rep(1,10) + rep(1,10)
library(tidyverse)
head(diamonds)
ggplot(data  = diamonds) + geom_boxplot(mapping = aes(x = cut, y = count()))
ggplot(data  = diamonds) + geom_boxplot(mapping = aes(x = cut, y = count)
)
ggplot(data  = diamonds) + geom_boxplot(mapping = aes(x = cut, y = carat))
diamond <- diamonds
mutate(diamond, countCut = count(cut))
diamonds %>% count(cut)
ggplot(data = diamond) + geom_histogram(mapping = aes(x = depth), binwidth = 0.5)
?wilcoxon.test
?wilcox.test()
diamond&depth
select(diamond, depth)
wilcox.test(select(diamond, depth))
typeof(select(diamond,depth))
x <- as.data.frame(select(diamond,depth))
typeof(x)
head(x)
wilcox.test(x)
class(as.data.frame(select(diamond, depth)))
x <- as.data.frame(select(diamond, depth))
head(x)
class(x)
typeof(x)
?shapiro.test()
shapiro.test(select(diamond, depth))
shapiro.test(as.data.frame(select(diamond,depth)))
shapiro.test(x)
is.numeric(x)
head(x)
class(x)
colnames(x)
?for
()
?for()
?map()
library(gapminder)
head(gapminder)
?round
?arrange
gapminder %>% arrange(gdpPercap)
gapminder %>% arrange(desc(gdpPercap))
gapminder %>% arrange(desc(gdpPercap), desc(pop))
gapminder %>% arrange(desc(pop))
?filter
gapminder %>% filter(country == "Netherlands")
gapminder %>% filter(country == "Netherlands") %>% arrange(year)
dutchData <- gapminder %>% filter(country == "Netherlands") %>% arrange(year)
dutchData
ggplot(data = dutchData) + geom_bar(mapping = aes(x = year, y = lifeExp))
ggplot(data = dutchData) + geom_histogram(mapping = aes(x = year, y = lifeExp))
ggplot(data = dutchData) + geom_plot(mapping = aes(x = year, y = lifeExp))
?ggplot2
ggplot(data = dutchData) + geom_line(mapping = aes(x = year, y = lifeExp))
NotFilterdutchData <- gapminder %>% filter(country == "Netherlands")
ggplot(data = NotFilterdutchData) + geom_line(mapping = aes(x = year, y = lifeExp))
Europe <- gapminder %>% filter(continent == "Europe")
ggplot(data = Europe) + geom_line(mapping = aes(x = year, y = lifeExp, colour = continent))
ggplot(data = Europe) + geom_line(mapping = aes(x = year, y = lifeExp, colour = country))
gapminder %>% filter(country == "Turkey")
gapminder %>% arrange(lifeExp)
gapminder %>% filter(year == 2007) %>% arrange(desc(lifeExp))
lifExp2007 <- gapminder %>% filter(year == 2007) %>% arrange(desc(lifeExp))
View(lifeExp2007)
View(lifExp2007)
lifExp2007 <- gapminder %>% filter(year == 2007) %>% arrange(desc(lifeExp)) %>% select(country, lifeExp)
?mutate
new <- gapminder %>% mutate(totalGdp = pop * gdpPercap)
new
new <- gapminder %>% mutate(totalGdp = pop * gdpPercap) %>% arrange(desc(totalGdp))
new
new <- gapminder %>% mutate(totalGdp = pop * gdpPercap) %>% filter(year == 2007) %>% arrange(desc(totalGdp))
new
new <- gapminder %>% mutate(totalGdp = pop * gdpPercap) %>% filter(year == 2007, continent == "Europe") %>% arrange(desc(totalGdp))
new
?signif
signif(1000,2)
signif(1000,2)/1000
library(modelr)
?bootstrap
mod <- lm(log(price) ~ log(carat), data = diamonds)
mod
summary(mod)
diamonds
diamonds %>%
mutate(lgprice = log(price), lgCarat = log(carat))
diamonds %>%
mutate(lgprice = log(price), lgCarat = log(carat)) %>%
select(lgprice, lgCarat)
diamonds %>%
mutate(lgprice = log(price), lgCarat = log(carat)) %>%
select(lgprice, lgCarat) %>%
ggplot() + geom_point(mapping = aes(x = lgprice, y = lgCarat))
tfData <- diamonds %>%
mutate(lgprice = log(price), lgCarat = log(carat)) %>%
select(lgprice, lgCarat)
tfData %>%
ggplot() + geom_point(mapping = aes(x = lgprice, y = lgCarat))
tfData
tfData %>%
lm(lgpric ~ lgCarat)
diamonds %>% lm(price ~ carat)
mod <- lm(lgprice ~ lgCarat, data = tfData)
diamonds %>% ggplot() + geom_point(mapping = aes(x = price, y = carat))
1/71
0.01408451*3600
3600/71
-1/(4*3600/71(1-40/(4*3600/71))) * log(0.99)
log(0.99)
-1/(4*3600/71(1-40/(4*3600/71)))
-1/(4*3600/71*(1-40/(4*3600/71))) * log(0.99)
1-6.172784e-05
?pnorm
qnorm(5/9,20,1)
qnorm(5/9,20,2)
qnorm(4/9,20,1)
qnorm(4/9,20,2)
?rpois
ppois(0.975,lambda = 200)
qpois(0.975,lambda = 200)
qpois(0.025,lambda = 200)
?qnorm
qnorm(5/9-20)
qnorm(5/9)
qnorm(5/9) + 20
qnorm(5/9)*sqrt(2) + 20
load("lda_user.rda")
?dist
jaccard.index(1:10, 2:20)
library(text2vec)
sim2(1:10,2:20, method = "cosine")
B = matrix(
c(2, 4, 3, 1, 5, 7),
nrow=3,
ncol=2)
C <- t(B)
sim2(B,C, method = "cosine")
x<-rnorm(10)
x<-matrix(x)
y<-matrix(rnorm(10*5),nrow=5)
x
y
install.packages("shiny")
install.packages("Shines")
install.packages("shinyjs")
install.packages("DT")
library(data.table)
data <- data.table::fread(input = "../dataset_mood_smartphone.csv",drop = 1)
ndcg <- function(label, id, predictions, k){
d <- data.frame(relevance = label, id=id, order = predictions, one=1)
d <- d[order(d$id, -d$relevance),]
d$co<-with(d, unlist(tapply(one, id, cumsum)))
d$v<-with(d, (2^relevance-1)/(log(co+1, 2)))
dcg0<-with(d[d$co<=k,], unlist(tapply(v, id, sum)))
d<-d[order(d$id, -d$order),]
d$co<-with(d, unlist(tapply(one, id, cumsum)))
d$v<-with(d, (2^relevance-1)/(log(co+1, 2)))
dcg<-with(d[d$co<=k,], unlist(tapply(v, id, sum)))
return(mean(dcg/dcg0))
}
predictions <- c(0.9, 0.7, 0.6,0.8,0.4,0,0.5,0 )
id <- c(1:8)
ndcg(label, id, predictions, 6)
label <- c(3,3,3,2,2,2,1,0)
ndcg(label, id, predictions, 6)
k=6
d <- data.frame(relevance = label, id=id, order = predictions, one=1)
d
id <- c(1,1,1,1,1,1,1,1)
d <- data.frame(relevance = label, id=id, order = predictions, one=1)
d
d <- d[order(d$id, -d$relevance),]
d
d$co<-with(d, unlist(tapply(one, id, cumsum)))
d$v<-with(d, (2^relevance-1)/(log(co+1, 2)))
dcg0<-with(d[d$co<=k,], unlist(tapply(v, id, sum)))
dcg0
d<-d[order(d$id, -d$order),]
d$co<-with(d, unlist(tapply(one, id, cumsum)))
d$v<-with(d, (2^relevance-1)/(log(co+1, 2)))
dcg<-with(d[d$co<=k,], unlist(tapply(v, id, sum)))
dcg
mean(dcg/dcg0)
d
d <- data.frame(relevance = label, id=id, order = predictions, one=1)
d
d <- d[order(d$id, -d$relevance),]
d$co<-with(d, unlist(tapply(one, id, cumsum)))
d
d$v<-with(d, (2^relevance-1)/(log(co+1, 2)))
d
2^(3)-1
log(2,2)
2^(3)-1
log(3,2)
7/log(3,2)
dcg0<-with(d[d$co<=k,], unlist(tapply(v, id, sum)))
d<-d[order(d$id, -d$order),]
d$co<-with(d, unlist(tapply(one, id, cumsum)))
d$v<-with(d, (2^relevance-1)/(log(co+1, 2)))
d
predictions <- c(0.9, 0, 0.6,0.8,0.3,0,0.4,0.5 )
d <- data.frame(relevance = label, id=id, order = predictions, one=1)
d <- d[order(d$id, -d$relevance),]
d$co<-with(d, unlist(tapply(one, id, cumsum)))
d$v<-with(d, (2^relevance-1)/(log(co+1, 2)))
dcg0<-with(d[d$co<=k,], unlist(tapply(v, id, sum)))
d<-d[order(d$id, -d$order),]
d$co<-with(d, unlist(tapply(one, id, cumsum)))
d$v<-with(d, (2^relevance-1)/(log(co+1, 2)))
d
dcg<-with(d[d$co<=k,], unlist(tapply(v, id, sum)))
mean(dcg/dcg0)
setwd("~/Desktop/Assignment2")
library(data.table)
data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
colnames(data)
keep_id <- unique(data$srch_id)
#split data random into train and test
dt <- sample(keep_id, train_instances*length(keep_id))
train <- subset(data, srch_id %in% dt)
test <- subset(data, !(srch_id %in% dt))
#split data into numerical and nominal values (check this!)
num <- train[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_length_of_stay","srch_booking_window","srch_adults_count","srch_children_count",
"srch_room_count","orig_destination_distance", "position")]
visit_star <- train[,c("visitor_hist_adr_usd")]
visit_usd <- train[,c("visitor_hist_adr_usd")]
visit_star[is.na(visit_star)] <- 0
visit_usd[is.na(visit_usd)] <- 0
nom <- train[,c("srch_id", "site_id", "visitor_location_country_id", "prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "srch_saturday_night_bool", "random_bool",
"comp2_rate", "comp2_inv", "comp3_rate", "comp3_inv", "comp5_rate", "comp5_inv", "comp8_rate", "comp8_inv")]
num_review <- train[,c("prop_review_score")]
num_median <- apply(num, 2, function(x) median(x, na.rm = TRUE))
nom_occur <- apply(nom, 2, function(x) names(which.max(table(x))))
numeric_median <- function(x, num_median){
for(i in 1:length(x[1,])){
x[,i][is.na(x[,i])] <- unname(num_median[i])
}
return(x)
}
nominal_occurence <- function(x, nom_occur){
for(i in 1:length(x[1,])){
x[,i][is.na(x[,i])] <- unname(nom_occur[i])
}
return(x)
}
num <- numeric_median(num, num_median)
nom <- nominal_occurence(nom, nom_occur)
#make numeric
nom <- as.data.frame(lapply(nom, function(x) as.numeric(as.character(x))))
#give relevance scores (clicked -> 1, booked -> 5 and other -> 0)
target <- train$booking_bool + train$click_bool
target[target==2] <- 5
train_set <- cbind(num, nom, target)
positionmedian <- with(train_set, tapply(position, prop_id, function(x) median(x)))
key <- data.frame(median_postition = unname(positionmedian), id = names(positionmedian))
train_set$estimate_position <- key[match(train_set$prop_id, key$id), "median_postition"]
train_set$position <- NULL
#feature engineering
#calculating differences with respect to mean of search query numerical values
train_set$propscore1diff <- with(train_set, unlist(tapply(prop_location_score1, srch_id, function(x) x-median(x))))
train_set$propscore2diff <- with(train_set, unlist(tapply(prop_location_score2, srch_id, function(x) x-median(x))))
train_set$propreviewscorediff <- with(train_set, unlist(tapply(prop_review_score, srch_id, function(x) x-median(x))))
train_set$propstarratingdiff <- with(train_set, unlist(tapply(prop_starrating, srch_id, function(x) x-median(x))))
train_set$priceusddiff <- with(train_set, unlist(tapply(price_usd, srch_id, function(x) x-median(x))))
train_set$visitusddiff <- train_set$price_usd - train_set$visit_usd
train_set$visitstardiff <- train_set$prop_starrating - train_set$visit_star
train_instances <- 0.8
keep_id <- unique(data$srch_id)
#split data random into train and test
dt <- sample(keep_id, train_instances*length(keep_id))
train <- subset(data, srch_id %in% dt)
test <- subset(data, !(srch_id %in% dt))
#split data into numerical and nominal values (check this!)
num <- train[,c("prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_length_of_stay","srch_booking_window","srch_adults_count","srch_children_count",
"srch_room_count","orig_destination_distance", "position")]
visit_star <- train[,c("visitor_hist_adr_usd")]
visit_usd <- train[,c("visitor_hist_adr_usd")]
visit_star[is.na(visit_star)] <- 0
visit_usd[is.na(visit_usd)] <- 0
nom <- train[,c("srch_id", "site_id", "visitor_location_country_id", "prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "srch_saturday_night_bool", "random_bool",
"comp2_rate", "comp2_inv", "comp3_rate", "comp3_inv", "comp5_rate", "comp5_inv", "comp8_rate", "comp8_inv")]
num_review <- train[,c("prop_review_score")]
num_median <- apply(num, 2, function(x) median(x, na.rm = TRUE))
nom_occur <- apply(nom, 2, function(x) names(which.max(table(x))))
numeric_median <- function(x, num_median){
for(i in 1:length(x[1,])){
x[,i][is.na(x[,i])] <- unname(num_median[i])
}
return(x)
}
nominal_occurence <- function(x, nom_occur){
for(i in 1:length(x[1,])){
x[,i][is.na(x[,i])] <- unname(nom_occur[i])
}
return(x)
}
num <- numeric_median(num, num_median)
nom <- nominal_occurence(nom, nom_occur)
#make numeric
nom <- as.data.frame(lapply(nom, function(x) as.numeric(as.character(x))))
#give relevance scores (clicked -> 1, booked -> 5 and other -> 0)
target <- train$booking_bool + train$click_bool
target[target==2] <- 5
train_set <- cbind(num, nom, target)
positionmedian <- with(train_set, tapply(position, prop_id, function(x) median(x)))
key <- data.frame(median_postition = unname(positionmedian), id = names(positionmedian))
train_set$estimate_position <- key[match(train_set$prop_id, key$id), "median_postition"]
train_set$position <- NULL
#feature engineering
#calculating differences with respect to mean of search query numerical values
train_set$propscore1diff <- with(train_set, unlist(tapply(prop_location_score1, srch_id, function(x) x-median(x))))
train_set$propscore2diff <- with(train_set, unlist(tapply(prop_location_score2, srch_id, function(x) x-median(x))))
train_set$propreviewscorediff <- with(train_set, unlist(tapply(prop_review_score, srch_id, function(x) x-median(x))))
train_set$propstarratingdiff <- with(train_set, unlist(tapply(prop_starrating, srch_id, function(x) x-median(x))))
train_set$priceusddiff <- with(train_set, unlist(tapply(price_usd, srch_id, function(x) x-median(x))))
train_set$visitusddiff <- train_set$price_usd - train_set$visit_usd
train_set$visitstardiff <- train_set$prop_starrating - train_set$visit_star
a <- train_set$price_usd - train_set$visit_usd
train_set$visitusddiff <- train_set$price_usd - visit_usd
train_set$visitstardiff <- train_set$prop_starrating - visit_star
colnames(train)
colnames(train_set)
#split data into numerical and nominal values (check this!)
num <- test[,c("visitor_hist_starrating","visitor_hist_adr_usd","prop_review_score","prop_location_score1","prop_location_score2", "prop_log_historical_price","price_usd",
"srch_length_of_stay","srch_booking_window","srch_adults_count","srch_children_count",
"srch_room_count","orig_destination_distance")]
visit_star <- test[,c("visitor_hist_adr_usd")]
visit_usd <- test[,c("visitor_hist_adr_usd")]
visit_star[is.na(visit_star)] <- 0
visit_usd[is.na(visit_usd)] <- 0
nom <- test[,c("srch_id", "site_id", "visitor_location_country_id", "prop_country_id", "prop_id", "prop_starrating",
"prop_brand_bool", "promotion_flag", "srch_destination_id", "srch_saturday_night_bool", "random_bool",
"comp2_rate", "comp2_inv", "comp3_rate", "comp3_inv", "comp5_rate", "comp5_inv", "comp8_rate", "comp8_inv")]
num <- numeric_median(num, num_median)
nom <- nominal_occurence(nom, nom_occur)
#make numeric
nom <- as.data.frame(lapply(nom, function(x) as.numeric(as.character(x))))
#give relevance scores (clicked -> 1, booked -> 5 and other -> 0)
target <- test$booking_bool + test$click_bool
target[target==2] <- 5
test_set <- cbind(num, nom, target)
d <- subset(test_set, !(test_set$prop_id %in% train_set$prop_id))
key2 <- data.frame(median_postition = median(positionmedian), id = as.factor(unique(d$prop_id)))
key_final <- rbind(key,key2)
#key_final <- subset(key_final, test_set$prop_id %in% key_final$id)
test_set$estimate_position <- key_final[match(test_set$prop_id, key_final$id), "median_postition"]
test_set$position <- NULL
test_set$propscore1diff <- with(test_set, unlist(tapply(prop_location_score1, srch_id, function(x) x-median(x))))
test_set$propscore2diff <- with(test_set, unlist(tapply(prop_location_score2, srch_id, function(x) x-median(x))))
test_set$propreviewscorediff <- with(test_set, unlist(tapply(prop_review_score, srch_id, function(x) x-median(x))))
test_set$propstarratingdiff <- with(test_set, unlist(tapply(prop_starrating, srch_id, function(x) x-median(x))))
test_set$priceusddiff <- with(test_set, unlist(tapply(price_usd, srch_id, function(x) x-median(x))))
test_set$visitusddiff <- test_set$price_usd - visit_usd
test_set$visitstardiff <- test_set$prop_starrating - visit_star
out <- list()
out$train <- train_set
out$test <- test_set
data_new <- out
setwd("~/Desktop/Assignment2/Version2/data_scripts_v2")
library(xgboost)
train <- data_new$train[order(data_new$train$srch_id),]
counts <- data.frame(table(train$srch_id))
colnames(train)
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,31)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,31)]))
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 0.1, nthread = 7, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
predictions <- predict(bst,dtest)
id <- data_new$test$srch_id
label <- data_new$test$target
source("Version2/ndcg_function.R")
setwd("~/Desktop/Assignment2")
source("Version2/ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
colnames(dtest)
source("Version2/data_scripts_v2/iteration10_v2.R")
data_new <- iteration10(data, 0.8)
#train xgboost
library(xgboost)
train <- data_new$train[order(data_new$train$srch_id),]
counts <- data.frame(table(train$srch_id))
colnames(data_new$test)
data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
#preprocess data
source("Version2/data_scripts_v2/iteration11_v2.R")
data_new <- iteration11(data, 0.8)
data <- data.table::fread(input = "../training_set_VU_DM_2014.csv", na.strings = c("NA", "NULL", "null"), data.table = FALSE)
#preprocess data
source("Version2/data_scripts_v2/iteration11_v2.R")
data_new <- iteration11(data, 0.8)
library(xgboost)
train <- data_new$train[order(data_new$train$srch_id),]
counts <- data.frame(table(train$srch_id))
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,31)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,31)]))
colnames(train)
colnames(data_new$train)
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,31)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,31)]))
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 0.1, nthread = 7, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
predictions <- predict(bst,dtest)
id <- data_new$test$srch_id
label <- data_new$test$target
source("Version2/ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
colnames(train)
metric
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,31,38,39)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,31,38,39)]))
dtrain <- xgb.DMatrix(as.matrix(train[,-c(12,31)]), label = train$target, group = counts$Freq)
dtest <- xgb.DMatrix(as.matrix(data_new$test[,-c(12,31)]))
bst <- xgb.train(data = dtrain, max.depth = 5, eta = 1, nthread = 7, nround = 100, objective = "rank:pairwise",
eval_metric = "ndcg", verbose = 3)
importance_matrix <- xgb.importance(colnames(dtrain),model = bst)
print(importance_matrix)
xgb.plot.importance(importance_matrix = importance_matrix)
predictions <- predict(bst,dtest)
id <- data_new$test$srch_id
label <- data_new$test$target
source("Version2/ndcg_function.R")
metric <- ndcg(label, id, predictions, 38)
metric
setwd("~/Desktop/Assignment2/Version2/iterations")
